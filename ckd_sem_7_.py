# -*- coding: utf-8 -*-
"""CKD SEM -7  .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15J_PHSbFdHArSnQsHQg6rxIYLdwCoA0V
"""

from google.colab import drive
drive.mount('/content/drive')

import os

DATASET_PATH = '/content/drive/MyDrive/PBL 2/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'

pip install tensorflow matplotlib scikit-learn opencv-python

import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from collections import Counter
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings("ignore")

DATASET_PATH = '/content/drive/MyDrive/PBL 2/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'
CLASSES = ['Normal', 'Cyst', 'Tumor', 'Stone']
IMG_SIZE = 150  # You can change to 224 if using pretrained models

images = []
labels = []

for label in CLASSES:
    folder_path = os.path.join(DATASET_PATH, label)
    for img_name in tqdm(os.listdir(folder_path), desc=f'Loading {label}'):
        try:
            img_path = os.path.join(folder_path, img_name)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            images.append(img)
            labels.append(label)
        except:
            continue

X = np.array(images)
y = np.array(labels)
print("Dataset loaded:", X.shape, len(y))

X = X / 255.0  # Normalize pixel values between 0 and 1

le = LabelEncoder()
y_encoded = le.fit_transform(y)
print("Class mapping:", dict(zip(le.classes_, le.transform(le.classes_))))

from collections import Counter
print("Original Class Distribution:", Counter(y_encoded))

from sklearn.utils import resample

def balance_data(X, y):
    df = pd.DataFrame({'label': y})
    max_count = df['label'].value_counts().max()

    X_balanced = []
    y_balanced = []

    for class_idx in np.unique(y):
        X_class = X[y == class_idx]
        y_class = y[y == class_idx]
        X_resampled, y_resampled = resample(
            X_class,
            y_class,
            replace=True,
            n_samples=max_count,
            random_state=42
        )
        X_balanced.extend(X_resampled)
        y_balanced.extend(y_resampled)

    return np.array(X_balanced), np.array(y_balanced)

X, y_encoded = balance_data(X, y_encoded)
print("Balanced class counts:", Counter(y_encoded))

X_train, X_val, y_train, y_val = train_test_split(
    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42
)

print("Train:", X_train.shape, "Val:", X_val.shape)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_aug = ImageDataGenerator(
    rotation_range=15,
    shear_range=0.1,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

val_aug = ImageDataGenerator()  # No augmentation for validation

def add_edge_features(X):
    edge_images = []
    for img in X:
        gray = cv2.cvtColor((img * 255).astype('uint8'), cv2.COLOR_RGB2GRAY)
        edge = cv2.Canny(gray, 100, 200)
        edge = edge / 255.0
        edge = np.expand_dims(edge, axis=-1)
        edge_images.append(edge)
    edge_images = np.array(edge_images)
    return np.concatenate([X, edge_images], axis=-1)  # new shape: (H, W, 4)

X_train = add_edge_features(X_train)
X_val = add_edge_features(X_val)
print("New input shape with edge feature:", X_train.shape)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

input_shape = X_train.shape[1:]  # e.g., (150, 150, 4)

model_cnn = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=input_shape),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(64, (3,3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(128, (3,3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])

model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model_cnn.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history_cnn = model_cnn.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=32,
    callbacks=[early_stop]
)

from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))
base_model.trainable = False  # Freeze feature extractor

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(4, activation='softmax')(x)

model_vgg = Model(inputs=base_model.input, outputs=output)
model_vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model_vgg.summary()

history_vgg = model_vgg.fit(
    X_train[:,:,:,:3],  # Remove edge channel for VGG
    y_train,
    validation_data=(X_val[:,:,:,:3], y_val),
    epochs=10,
    batch_size=32,
    callbacks=[early_stop]
)

def get_gradcam_heatmap(model, image, last_conv_layer_name, pred_index=None):
    grad_model = tf.keras.models.Model([model.inputs],
                                       [model.get_layer(last_conv_layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(np.expand_dims(image, axis=0))
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def display_gradcam(image, label_index, model, last_conv_layer):
    # Check if the model is VGG and slice the image accordingly
    if model.name.startswith('functional'): # Assuming VGG is 'functional' based on model.summary()
        heatmap = get_gradcam_heatmap(model, image[:,:,:3], last_conv_layer)
    else:
        heatmap = get_gradcam_heatmap(model, image, last_conv_layer)

    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))
    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)

    image_rgb = (image[:,:,:3] * 255).astype("uint8")
    superimposed_img = cv2.addWeighted(image_rgb, 0.6, heatmap_color, 0.4, 0)

    plt.imshow(superimposed_img)
    plt.title(f"Grad-CAM - Predicted: {le.inverse_transform([label_index])[0]}")
    plt.axis('off')
    plt.show()

sample_img = X_val[0]
pred = model_vgg.predict(np.expand_dims(sample_img[:,:,:3], axis=0))
display_gradcam(sample_img, np.argmax(pred), model_vgg, 'block5_conv3')  # For VGG

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Predict
y_pred_prob = model_vgg.predict(X_val[:,:,:,:3])
y_pred = np.argmax(y_pred_prob, axis=1)

# Classification Report
report = classification_report(y_val, y_pred, target_names=le.classes_, output_dict=True)
df_report = pd.DataFrame(report).transpose()

# Display
print(df_report)

# Confusion Matrix
cm = confusion_matrix(y_val, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import RocCurveDisplay

# One-hot encode ground truth
y_val_bin = label_binarize(y_val, classes=[0,1,2,3])
n_classes = y_val_bin.shape[1]

fpr = {}
tpr = {}
roc_auc = {}

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_pred_prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot all ROC curves
plt.figure(figsize=(8, 6))
colors = ['blue', 'green', 'red', 'orange']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color,
             label=f"Class {le.inverse_transform([i])[0]} (AUC = {roc_auc[i]:.2f})")

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC AUC Curve ')
plt.legend(loc='lower right')
plt.grid()
plt.show()

# Accuracy
plt.plot(history_vgg.history['accuracy'], label='Train Accuracy', color='green')
plt.plot(history_vgg.history['val_accuracy'], label='Val Accuracy', color='blue')
plt.title('Model Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss
plt.plot(history_vgg.history['loss'], label='Train Loss', color='red')
plt.plot(history_vgg.history['val_loss'], label='Val Loss', color='purple')
plt.title('Model Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# Assuming y_raw was original label list before SMOTE
sns.countplot(x=le.inverse_transform(y_val), palette='Set2')
plt.title("Validation Set Class Distribution")
plt.xlabel("Class")
plt.ylabel("Frequency")
plt.xticks(rotation=10)
plt.show()

plt.savefig("roc_auc_curve.png", dpi=300, bbox_inches='tight')  # Save any plot

from sklearn.metrics import precision_recall_curve, average_precision_score
from sklearn.preprocessing import label_binarize

# Binarize labels for PR curve
y_val_bin = label_binarize(y_val, classes=[0, 1, 2, 3])
n_classes = y_val_bin.shape[1]

# Predict probabilities for VGG16 or CNN
y_score_vgg = model_vgg.predict(X_val[:,:,:,:3])
# y_score_cnn = model_cnn.predict(X_val)

# Precision-Recall curve
plt.figure(figsize=(8, 6))
colors = ['red', 'green', 'blue', 'orange']

for i, color in zip(range(n_classes), colors):
    precision, recall, _ = precision_recall_curve(y_val_bin[:, i], y_score_vgg[:, i])
    ap_score = average_precision_score(y_val_bin[:, i], y_score_vgg[:, i])
    plt.plot(recall, precision, color=color, label=f'{le.classes_[i]} (AP = {ap_score:.2f})')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve (VGG16)")
plt.legend(loc='best')
plt.grid(True)
plt.show()

indices = [5, 15, 25, 40]  # Pick random indexes from validation set

for idx in indices:
    img_rgb = X_val[idx][:,:,:3]
    img_full = X_val[idx]

    # VGG16 Grad-CAM
    pred = model_vgg.predict(np.expand_dims(img_rgb, axis=0))
    pred_label = np.argmax(pred)
    display_gradcam(img_rgb, pred_label, model_vgg, last_conv_layer='block5_conv3')

    # CNN Grad-CAM
    pred = model_cnn.predict(np.expand_dims(img_full, axis=0))
    pred_label = np.argmax(pred)
    display_gradcam(img_full, pred_label, model_cnn, last_conv_layer='dense_1')  # adjust layer if needed

from sklearn.metrics import confusion_matrix
import seaborn as sns

y_pred_vgg = np.argmax(model_vgg.predict(X_val[:,:,:,:3]), axis=1)
cm_vgg = confusion_matrix(y_val, y_pred_vgg)

plt.figure(figsize=(6,5))
sns.heatmap(cm_vgg, annot=True, cmap='Greens', fmt='d',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix - VGG16")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Flatten features
X_flat = X_val.reshape(X_val.shape[0], -1)  # shape (N, 150*150*4)

# Option 1: PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(StandardScaler().fit_transform(X_flat))

# Option 2: t-SNE
tsne = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne = tsne.fit_transform(X_flat)

# Plot both
fig, axs = plt.subplots(1, 2, figsize=(14, 6))

# PCA
sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=le.inverse_transform(y_val),
                palette='Set1', ax=axs[0])
axs[0].set_title("PCA - Feature Space Clustering")

# t-SNE
sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=le.inverse_transform(y_val),
                palette='Set2', ax=axs[1])
axs[1].set_title("t-SNE - Feature Space Clustering")

plt.tight_layout()
plt.show()

# For Deep Learning (Keras)
model_vgg.save("ckd_model_vgg.h5")

# For Deep Learning (Keras)
model_vgg.save("ckd_model_vgg.keras")

# Save the CNN model
model_cnn.save("ckd_model_cnn.keras")

import os

# Define the directory in Google Drive where you want to save the models
# You might want to create a specific folder for your project
drive_save_path = '/content/drive/MyDrive/PBL 2/trained_models'

# Create the directory if it doesn't exist
os.makedirs(drive_save_path, exist_ok=True)

# Save the VGG16 model
vgg_model_save_path = os.path.join(drive_save_path, "ckd_model_vgg.keras")
model_vgg.save(vgg_model_save_path)
print(f"VGG16 model saved to: {vgg_model_save_path}")

# Save the CNN model
cnn_model_save_path = os.path.join(drive_save_path, "ckd_model_cnn.keras")
model_cnn.save(cnn_model_save_path)
print(f"CNN model saved to: {cnn_model_save_path}")